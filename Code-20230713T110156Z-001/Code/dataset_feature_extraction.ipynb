{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cF8Wy9srqOPp",
        "outputId": "0061047e-bfbf-4f83-8755-7b51b6cf0aa0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "# mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YLsZ8AUz_E6X"
      },
      "outputs": [],
      "source": [
        "pip install tsfresh"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WP_oZqJCDI9q"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "dataset=pd.DataFrame()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tDuEEGkAqr_A",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "outputId": "31e1d930-bf20-4be8-a8ad-8791388a827c"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-7c2f8a3df698>\u001b[0m in \u001b[0;36m<cell line: 15>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m                     \u001b[0;31m# Load the input image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m                     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m                     \u001b[0;31m# Convert the image to grayscale\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m                     \u001b[0mgray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCOLOR_BGR2GRAY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "from google.colab.patches import cv2_imshow\n",
        "import matplotlib.pyplot as plt\n",
        "import tsfresh\n",
        "from tsfresh import extract_features\n",
        "import tsfresh.feature_extraction.feature_calculators as fc\n",
        "\n",
        "main_path = '/content/gdrive/MyDrive/Project Gait Analysis/Dataset/GaitDatasetA-silh'\n",
        "persons = os.listdir(main_path)\n",
        "\n",
        "for person in persons:\n",
        "            person_path = os.path.join(main_path, person)\n",
        "            walks = os.listdir(person_path)\n",
        "            for walk in walks:\n",
        "                walk_path = os.path.join(person_path, walk)\n",
        "\n",
        "                types = os.listdir(walk_path)\n",
        "                full=[]\n",
        "                cropL=[]\n",
        "                for typeper in types:\n",
        "                    new_path = os.path.join(walk_path, typeper)\n",
        "                    l=new_path.split('/')\n",
        "                    import cv2\n",
        "\n",
        "                    # Load the input image\n",
        "                    img = cv2.imread(new_path)\n",
        "                    # Convert the image to grayscale\n",
        "                    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "                    # Apply binary thresholding\n",
        "                    ret, thresh = cv2.threshold(gray, 127, 255, cv2.THRESH_BINARY)\n",
        "\n",
        "                    # Find contours in the binary image\n",
        "                    contours, hierarchy = cv2.findContours(thresh, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
        "\n",
        "                    # Find the biggest contour\n",
        "                    biggest_contour = max(contours, key=cv2.contourArea)\n",
        "\n",
        "                    # Draw the biggest contour on the original image\n",
        "                    cv2.drawContours(img, [biggest_contour], -1, (0, 255, 0), 2)\n",
        "\n",
        "                    # Get the bounding box for the contour\n",
        "                    x, y, w, h = cv2.boundingRect(biggest_contour)\n",
        "\n",
        "                    # Crop the image to the bounding box\n",
        "                    crop = img[y:y+h, x:x+w]\n",
        "\n",
        "                    # Remove the green color from the contour highlight\n",
        "                    crop[np.where((crop == [0, 255, 0]).all(axis=2))] = [0, 0, 0]\n",
        "\n",
        "                    # Save the cropped image\n",
        "                    cv2.imwrite('/content/gdrive/MyDrive/Project Gait Analysis/Result/CROPPED IMAGES/cropped_img' +':'+ l[-1], crop)\n",
        "                    #cv2_imshow(crop)\n",
        "\n",
        "                    full.append(new_path)\n",
        "                    cropL.append('/content/gdrive/MyDrive/Project Gait Analysis/Result/CROPPED IMAGES/cropped_img' +':'+ l[-1])\n",
        "\n",
        "                # Define the directory where the images are located\n",
        "                image_dir = person_path\n",
        "\n",
        "                # Get a list of all the image file names in the directory\n",
        "                image_filenames = os.listdir(image_dir)\n",
        "                '''\n",
        "                # Iterate over each image file\n",
        "                for image_filename in image_filenames:\n",
        "                    # Load the image\n",
        "                    image = cv2.imread(os.path.join(image_dir, image_filename))\n",
        "\n",
        "                    # Convert the image to a numpy array\n",
        "                    image_array = np.array(image)\n",
        "\n",
        "                    # Change the data type of the array to float32\n",
        "                    image_array = image_array.astype('float32')\n",
        "\n",
        "                    # Normalize the array\n",
        "                    image_array = cv2.normalize(image_array, None, 0, 1, cv2.NORM_MINMAX)\n",
        "\n",
        "                # Load images into a list\n",
        "                images = [Image.open(f) for f in full]\n",
        "                # Convert images  mto NumPy arrays\n",
        "                image_arrays = [np.array(image) for image in images]\n",
        "\n",
        "                # Calculate average of the images\n",
        "                average_image = np.mean(image_arrays, axis=0)\n",
        "\n",
        "                # Convert average image back to an Image object\n",
        "                #average_image = Image.fromarray(np.uint8(average_image))\n",
        "\n",
        "                # Save the average image\n",
        "                #average_image.save('Average_image.jpg')\n",
        "                cv2.imwrite(\"/content/gdrive/MyDrive/Project Gait Analysis/Result/Average Full Image/average_image_full.jpg\", average_image)\n",
        "                #cv2_imshow(average_image)\n",
        "\n",
        "                # Define the directory where the images are located\n",
        "                image_dir = '/content/gdrive/MyDrive/Project Gait Analysis/Result/CROPPED IMAGES'\n",
        "\n",
        "                # Get a list of all the image file names in the directory\n",
        "                image_filenames = os.listdir(image_dir)\n",
        "\n",
        "                # Iterate over each image file\n",
        "                for image_filename in image_filenames:\n",
        "                    # Load the image\n",
        "                    image = cv2.imread(os.path.join(image_dir, image_filename))\n",
        "\n",
        "                    # Convert the image to a numpy array\n",
        "                    image_array = np.array(image)\n",
        "\n",
        "                    # Change the data type of the array to float32\n",
        "                    image_array = image_array.astype('float32')\n",
        "\n",
        "                    # Normalize the array\n",
        "                    image_array = cv2.normalize(image_array, None, 0, 1, cv2.NORM_MINMAX)\n",
        "\n",
        "                # Load images into a list\n",
        "                images = [Image.open(f) for f in cropL]\n",
        "\n",
        "                # Get the size of the largest image\n",
        "                max_size = (0, 0)\n",
        "                for image in images:\n",
        "                    if image.size[0] > max_size[0]:\n",
        "                        max_size = image.size\n",
        "\n",
        "                # Resize all images to the size of the largest image\n",
        "                resized_images = [image.resize(max_size) for image in images]\n",
        "\n",
        "                # Convert images to NumPy arrays\n",
        "                image_arrays = [np.array(image) for image in resized_images]\n",
        "\n",
        "                # Calculate average of the images\n",
        "                average_image = np.mean(image_arrays, axis=0)\n",
        "\n",
        "                # Convert the average image to 8-bit integers\n",
        "                average_image = np.uint8(average_image)\n",
        "\n",
        "                #convert to  cv2 format\n",
        "                average_image = cv2.cvtColor(average_image, cv2.COLOR_RGB2BGR)\n",
        "\n",
        "                # Save the average image\n",
        "                cv2.imwrite(\"/content/gdrive/MyDrive/Project Gait Analysis/Result/Average cropped image/average_image_full.jpg\", average_image)\n",
        "                #cv2_imshow(average_image)\n",
        "            '''\n",
        "\n",
        "                head_cen_x=[]\n",
        "                head_cen_y=[]\n",
        "                legs_cen_x=[]\n",
        "                legs_cen_y=[]\n",
        "                torso_cen_x=[]\n",
        "                torso_cen_y=[]\n",
        "                for i in cropL:\n",
        "                  new_path = i\n",
        "                # Load the image\n",
        "                  img = cv2.imread(new_path)\n",
        "                  # Convert the image to grayscale\n",
        "                  gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "                  # Apply binary thresholding\n",
        "                  ret, thresh = cv2.threshold(gray, 127, 255, cv2.THRESH_BINARY)\n",
        "\n",
        "                  # Find contours in the binary image\n",
        "                  contours, hierarchy = cv2.findContours(thresh, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
        "\n",
        "                  # Find the biggest contour\n",
        "                  biggest_contour = max(contours, key=cv2.contourArea)\n",
        "\n",
        "                # Get the bounding box of the person\n",
        "                  x, y, w, h = cv2.boundingRect(biggest_contour)\n",
        "\n",
        "                # Divide the bounding box into three regions (head, torso, legs)\n",
        "                  head = img[y:y+h//5, x:x+w]\n",
        "                  torso = img[y+h//5:y+(2*h)//4, x:x+w]\n",
        "                  legs = img[y+(2*h)//4:y+h, x:x+w]\n",
        "\n",
        "                  l=new_path.split(':')\n",
        "\n",
        "                # Save the regions\n",
        "                  cv2.imwrite(\"/content/gdrive/MyDrive/Project Gait Analysis/Result/head/head\" +':'+ l[-1], head)\n",
        "                  #cv2_imshow(head)\n",
        "                  cv2.imwrite(\"/content/gdrive/MyDrive/Project Gait Analysis/Result/torso/torso\" +':'+ l[-1], torso)\n",
        "                  #cv2_imshow(torso)\n",
        "                  cv2.imwrite(\"/content/gdrive/MyDrive/Project Gait Analysis/Result/legs/legs\" +':'+ l[-1], legs)\n",
        "                  #cv2_imshow(legs)\n",
        "\n",
        "\n",
        "                  new_path = \"/content/gdrive/MyDrive/Project Gait Analysis/Result/head/head\" +':'+ l[-1]\n",
        "                  # Load image\n",
        "                  image = cv2.imread(new_path)\n",
        "\n",
        "                  # Convert image to grayscale\n",
        "                  gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "                  # Threshold image to create a binary image\n",
        "                  ret, thresh = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n",
        "\n",
        "                  # Find contours in the binary image\n",
        "                  contours, hierarchy = cv2.findContours(thresh, cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)\n",
        "\n",
        "                  # Find the largest contour (assuming it corresponds to the body)\n",
        "                  largest_contour = max(contours, key=cv2.contourArea)\n",
        "\n",
        "                  # Find the moments of the largest contour\n",
        "                  moments = cv2.moments(largest_contour)\n",
        "                  # Calculate the centroid of the contour\n",
        "                  centroid_x = int(moments[\"m10\"] / moments[\"m00\"])\n",
        "                  centroid_y = int(moments[\"m01\"] / moments[\"m00\"])\n",
        "\n",
        "                  #append centroid in list\n",
        "                  head_cen_x.append(centroid_x)\n",
        "                  head_cen_y.append(centroid_y)\n",
        "\n",
        "                  # Print the centroid\n",
        "                  #print(\"Centroid of the body: (\", centroid_x, \",\", centroid_y, \")\")\n",
        "\n",
        "                  new_path = \"/content/gdrive/MyDrive/Project Gait Analysis/Result/torso/torso\" +':'+ l[-1]\n",
        "                  # Load image\n",
        "                  image = cv2.imread(new_path)\n",
        "\n",
        "                  # Convert image to grayscale\n",
        "                  gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "                  # Threshold image to create a binary image\n",
        "                  ret, thresh = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n",
        "\n",
        "                  # Find contours in the binary image\n",
        "                  contours, hierarchy = cv2.findContours(thresh, cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)\n",
        "\n",
        "                  # Find the largest contour (assuming it corresponds to the body)\n",
        "                  largest_contour = max(contours, key=cv2.contourArea)\n",
        "\n",
        "                  # Find the moments of the largest contour\n",
        "                  moments = cv2.moments(largest_contour)\n",
        "                  # Calculate the centroid of the contour\n",
        "                  centroid_x = int(moments[\"m10\"] / moments[\"m00\"])\n",
        "                  centroid_y = int(moments[\"m01\"] / moments[\"m00\"])\n",
        "\n",
        "                  #append centroid in list\n",
        "                  torso_cen_x.append(centroid_x)\n",
        "                  torso_cen_y.append(centroid_y)\n",
        "\n",
        "                  # Print the centroid\n",
        "                  #print(\"Centroid of the body: (\", centroid_x, \",\", centroid_y, \")\")\n",
        "\n",
        "                  new_path = \"/content/gdrive/MyDrive/Project Gait Analysis/Result/legs/legs\" +':'+ l[-1]\n",
        "                  # Load image\n",
        "                  image = cv2.imread(new_path)\n",
        "\n",
        "                  # Convert image to grayscale\n",
        "                  gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "                  # Threshold image to create a binary image\n",
        "                  ret, thresh = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n",
        "\n",
        "                  # Find contours in the binary image\n",
        "                  contours, hierarchy = cv2.findContours(thresh, cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)\n",
        "\n",
        "                  # Find the largest contour (assuming it corresponds to the body)\n",
        "                  largest_contour = max(contours, key=cv2.contourArea)\n",
        "\n",
        "                  # Find the moments of the largest contour\n",
        "                  moments = cv2.moments(largest_contour)\n",
        "\n",
        "                  # Calculate the centroid of the contour\n",
        "                  centroid_x = int(moments[\"m10\"] / moments[\"m00\"])\n",
        "                  centroid_y = int(moments[\"m01\"] / moments[\"m00\"])\n",
        "\n",
        "                  #append centroid in list\n",
        "                  legs_cen_x.append(centroid_x)\n",
        "                  legs_cen_y.append(centroid_y)\n",
        "\n",
        "                  # Print the centroid\n",
        "                  #print(\"Centroid of the body: (\", centroid_x, \",\", centroid_y, \")\")\n",
        "\n",
        "                '''x=[]\n",
        "                for i in range(0,len(cropL)):\n",
        "                  x.append(i)\n",
        "                y1=head_cen_y\n",
        "                y2=torso_cen_y\n",
        "                y3=legs_cen_y\n",
        "                plt.plot(x, y1, label='head_y')\n",
        "                plt.plot(x, y2, label='torso_y')\n",
        "                plt.plot(x, y3, label='legs_y')\n",
        "\n",
        "                # Add legend and axis labels\n",
        "                plt.legend()\n",
        "                plt.xlabel('X-axis')\n",
        "                plt.ylabel('Y-axis')\n",
        "\n",
        "                # Plot the data\n",
        "                #plt.plot(x, y)\n",
        "\n",
        "                plt.show()     '''\n",
        "\n",
        "                # Convert the list to a pandas DataFrame\n",
        "                df_head = pd.DataFrame({'id': 'head', 'time': range(len(head_cen_x)), 'x':head_cen_x, 'y':head_cen_y})\n",
        "                df_torso=pd.DataFrame({'id': 'torso', 'time': range(len(torso_cen_x)), 'x':torso_cen_x, 'y':torso_cen_y})\n",
        "                df_legs=pd.DataFrame({'id': 'legs', 'time': range(len(legs_cen_x)), 'x':legs_cen_x, 'y':legs_cen_y})\n",
        "                df=pd.concat([df_head, df_torso,df_legs],axis=0)\n",
        "                #print(df)\n",
        "\n",
        "                timeseries = [head_cen_x, head_cen_y, torso_cen_x, torso_cen_y, legs_cen_x, legs_cen_y]\n",
        "                df_features = pd.DataFrame()\n",
        "\n",
        "                for i, series in enumerate(timeseries):\n",
        "                    arr = np.array(series)\n",
        "                    a = fc.abs_energy(arr)\n",
        "                    b = fc.mean(arr)\n",
        "                    c = fc.kurtosis(arr)\n",
        "                    d = fc.standard_deviation(arr)\n",
        "                    e = fc.skewness(arr)\n",
        "\n",
        "                    features = {'abs_energy': a, 'mean': b, 'sample_entropy': c, 'standard_deviation': d, 'skewness': e}\n",
        "                    df = pd.DataFrame(features, index=[i])\n",
        "                    df_features = pd.concat([df_features, df])\n",
        "                l=walk_path.split('/')\n",
        "\n",
        "                df_id = pd.DataFrame({'id': [l[-2]+'-'+l[-1]]})\n",
        "                df_id = df_id.reindex(df_features.index)  # Make sure the index matches df_features\n",
        "\n",
        "                df_features = pd.concat([df_id, df_features], axis=1)\n",
        "\n",
        "                # Set the 'time' column\n",
        "                #df_features['time'] = ['5'] * len(df_features)\n",
        "\n",
        "                # Reshape the DataFrame to have a single row and 30 columns\n",
        "                df_features = df_features.stack().reset_index(drop=True).to_frame().T\n",
        "\n",
        "                # Display the DataFrame\n",
        "                #print(df_features)\n",
        "\n",
        "                dataset=pd.concat([dataset,df_features],axis=0,ignore_index=True)\n",
        "print(dataset)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "from google.colab.patches import cv2_imshow\n",
        "import matplotlib.pyplot as plt\n",
        "import tsfresh\n",
        "from tsfresh import extract_features\n",
        "import tsfresh.feature_extraction.feature_calculators as fc\n",
        "\n",
        "main_path = '/content/gdrive/MyDrive/Project Gait Analysis/Dataset/GaitDatasetA-silh'\n",
        "persons = os.listdir(main_path)\n",
        "\n",
        "for person in persons:\n",
        "            person_path = os.path.join(main_path, person)\n",
        "            walks = os.listdir(person_path)\n",
        "            for walk in walks:\n",
        "                walk_path = os.path.join(person_path, walk)\n",
        "\n",
        "                types = os.listdir(walk_path)\n",
        "                full=[]\n",
        "                cropL=[]\n",
        "                for typeper in types:\n",
        "                    new_path = os.path.join(walk_path, typeper)\n",
        "                    l=new_path.split('/')\n",
        "                    import cv2\n",
        "\n",
        "                    # Load the input image\n",
        "                    img = cv2.imread(new_path)\n",
        "                    # Convert the image to grayscale\n",
        "                    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "                    # Apply binary thresholding\n",
        "                    ret, thresh = cv2.threshold(gray, 127, 255, cv2.THRESH_BINARY)\n",
        "\n",
        "                    # Find contours in the binary image\n",
        "                    contours, hierarchy = cv2.findContours(thresh, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
        "\n",
        "                    # Find the biggest contour\n",
        "                    biggest_contour = max(contours, key=cv2.contourArea)\n",
        "\n",
        "                    # Draw the biggest contour on the original image\n",
        "                    cv2.drawContours(img, [biggest_contour], -1, (0, 255, 0), 2)\n",
        "\n",
        "                    # Get the bounding box for the contour\n",
        "                    x, y, w, h = cv2.boundingRect(biggest_contour)\n",
        "\n",
        "                    # Crop the image to the bounding box\n",
        "                    crop = img[y:y+h, x:x+w]\n",
        "\n",
        "                    # Remove the green color from the contour highlight\n",
        "                    crop[np.where((crop == [0, 255, 0]).all(axis=2))] = [0, 0, 0]\n",
        "\n",
        "                    # Save the cropped image\n",
        "                    cv2.imwrite('/content/gdrive/MyDrive/Project Gait Analysis/Result/CROPPED IMAGES/cropped_img' +':'+ l[-1], crop)\n",
        "                    #cv2_imshow(crop)\n",
        "\n",
        "                    full.append(new_path)\n",
        "                    cropL.append('/content/gdrive/MyDrive/Project Gait Analysis/Result/CROPPED IMAGES/cropped_img' +':'+ l[-1])\n",
        "\n",
        "                head_cen_x=[]\n",
        "                head_cen_y=[]\n",
        "                legs_cen_x=[]\n",
        "                legs_cen_y=[]\n",
        "                torso_cen_x=[]\n",
        "                torso_cen_y=[]\n",
        "                for i in cropL:\n",
        "                  new_path = i\n",
        "                # Load the image\n",
        "                  img = cv2.imread(new_path)\n",
        "                  # Convert the image to grayscale\n",
        "                  gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "                  # Apply binary thresholding\n",
        "                  ret, thresh = cv2.threshold(gray, 127, 255, cv2.THRESH_BINARY)\n",
        "\n",
        "                  # Find contours in the binary image\n",
        "                  contours, hierarchy = cv2.findContours(thresh, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
        "\n",
        "                  # Find the biggest contour\n",
        "                  biggest_contour = max(contours, key=cv2.contourArea)\n",
        "\n",
        "                # Get the bounding box of the person\n",
        "                  x, y, w, h = cv2.boundingRect(biggest_contour)\n",
        "\n",
        "                # Divide the bounding box into three regions (head, torso, legs)\n",
        "                  head = img[y:y+h//5, x:x+w]\n",
        "                  torso = img[y+h//5:y+(2*h)//4, x:x+w]\n",
        "                  legs = img[y+(2*h)//4:y+h, x:x+w]\n",
        "\n",
        "                  l=new_path.split(':')\n",
        "\n",
        "                # Save the regions\n",
        "                  cv2.imwrite(\"/content/gdrive/MyDrive/Project Gait Analysis/Result/head/head\" +':'+ l[-1], head)\n",
        "                  #cv2_imshow(head)\n",
        "                  cv2.imwrite(\"/content/gdrive/MyDrive/Project Gait Analysis/Result/torso/torso\" +':'+ l[-1], torso)\n",
        "                  #cv2_imshow(torso)\n",
        "                  cv2.imwrite(\"/content/gdrive/MyDrive/Project Gait Analysis/Result/legs/legs\" +':'+ l[-1], legs)\n",
        "                  #cv2_imshow(legs)\n",
        "\n",
        "\n",
        "                  new_path = \"/content/gdrive/MyDrive/Project Gait Analysis/Result/head/head\" +':'+ l[-1]\n",
        "                  # Load image\n",
        "                  image = cv2.imread(new_path)\n",
        "\n",
        "                  # Convert image to grayscale\n",
        "                  gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "                  # Threshold image to create a binary image\n",
        "                  ret, thresh = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n",
        "\n",
        "                  # Find contours in the binary image\n",
        "                  contours, hierarchy = cv2.findContours(thresh, cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)\n",
        "\n",
        "                  # Find the largest contour (assuming it corresponds to the body)\n",
        "                  largest_contour = max(contours, key=cv2.contourArea)\n",
        "\n",
        "                  # Find the moments of the largest contour\n",
        "                  moments = cv2.moments(largest_contour)\n",
        "                  # Calculate the centroid of the contour\n",
        "                  centroid_x = int(moments[\"m10\"] / moments[\"m00\"])\n",
        "                  centroid_y = int(moments[\"m01\"] / moments[\"m00\"])\n",
        "\n",
        "                  #append centroid in list\n",
        "                  head_cen_x.append(centroid_x)\n",
        "                  head_cen_y.append(centroid_y)\n",
        "\n",
        "                  # Print the centroid\n",
        "                  #print(\"Centroid of the body: (\", centroid_x, \",\", centroid_y, \")\")\n",
        "\n",
        "                  new_path = \"/content/gdrive/MyDrive/Project Gait Analysis/Result/torso/torso\" +':'+ l[-1]\n",
        "                  # Load image\n",
        "                  image = cv2.imread(new_path)\n",
        "\n",
        "                  # Convert image to grayscale\n",
        "                  gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "                  # Threshold image to create a binary image\n",
        "                  ret, thresh = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n",
        "\n",
        "                  # Find contours in the binary image\n",
        "                  contours, hierarchy = cv2.findContours(thresh, cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)\n",
        "\n",
        "                  # Find the largest contour (assuming it corresponds to the body)\n",
        "                  largest_contour = max(contours, key=cv2.contourArea)\n",
        "\n",
        "                  # Find the moments of the largest contour\n",
        "                  moments = cv2.moments(largest_contour)\n",
        "                  # Calculate the centroid of the contour\n",
        "                  centroid_x = int(moments[\"m10\"] / moments[\"m00\"])\n",
        "                  centroid_y = int(moments[\"m01\"] / moments[\"m00\"])\n",
        "\n",
        "                  #append centroid in list\n",
        "                  torso_cen_x.append(centroid_x)\n",
        "                  torso_cen_y.append(centroid_y)\n",
        "\n",
        "                  # Print the centroid\n",
        "                  #print(\"Centroid of the body: (\", centroid_x, \",\", centroid_y, \")\")\n",
        "\n",
        "                  new_path = \"/content/gdrive/MyDrive/Project Gait Analysis/Result/legs/legs\" +':'+ l[-1]\n",
        "                  # Load image\n",
        "                  image = cv2.imread(new_path)\n",
        "\n",
        "                  # Convert image to grayscale\n",
        "                  gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "                  # Threshold image to create a binary image\n",
        "                  ret, thresh = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n",
        "\n",
        "                  # Find contours in the binary image\n",
        "                  contours, hierarchy = cv2.findContours(thresh, cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)\n",
        "\n",
        "                  # Find the largest contour (assuming it corresponds to the body)\n",
        "                  largest_contour = max(contours, key=cv2.contourArea)\n",
        "\n",
        "                  # Find the moments of the largest contour\n",
        "                  moments = cv2.moments(largest_contour)\n",
        "\n",
        "                  # Calculate the centroid of the contour\n",
        "                  centroid_x = int(moments[\"m10\"] / moments[\"m00\"])\n",
        "                  centroid_y = int(moments[\"m01\"] / moments[\"m00\"])\n",
        "\n",
        "                  #append centroid in list\n",
        "                  legs_cen_x.append(centroid_x)\n",
        "                  legs_cen_y.append(centroid_y)\n",
        "\n",
        "                # Convert the list to a pandas DataFrame\n",
        "                df_head = pd.DataFrame({'id': 'head', 'time': range(len(head_cen_x)), 'x':head_cen_x, 'y':head_cen_y})\n",
        "                df_torso=pd.DataFrame({'id': 'torso', 'time': range(len(torso_cen_x)), 'x':torso_cen_x, 'y':torso_cen_y})\n",
        "                df_legs=pd.DataFrame({'id': 'legs', 'time': range(len(legs_cen_x)), 'x':legs_cen_x, 'y':legs_cen_y})\n",
        "                df=pd.concat([df_head, df_torso,df_legs],axis=0)\n",
        "                #print(df)\n",
        "\n",
        "                timeseries = [head_cen_x, head_cen_y, torso_cen_x, torso_cen_y, legs_cen_x, legs_cen_y]\n",
        "                df_features = pd.DataFrame()\n",
        "\n",
        "                for i, series in enumerate(timeseries):\n",
        "                    arr = np.array(series)\n",
        "                    a = fc.abs_energy(arr)\n",
        "                    b = fc.mean(arr)\n",
        "                    c = fc.kurtosis(arr)\n",
        "                    d = fc.standard_deviation(arr)\n",
        "                    e = fc.skewness(arr)\n",
        "\n",
        "                    features = {'abs_energy': a, 'mean': b, 'sample_entropy': c, 'standard_deviation': d, 'skewness': e}\n",
        "                    df = pd.DataFrame(features, index=[i])\n",
        "                    df_features = pd.concat([df_features, df])\n",
        "                l=walk_path.split('/')\n",
        "\n",
        "                df_id = pd.DataFrame({'id': [l[-2]+'-'+l[-1]]})\n",
        "                df_id = df_id.reindex(df_features.index)  # Make sure the index matches df_features\n",
        "\n",
        "                df_features = pd.concat([df_id, df_features], axis=1)\n",
        "\n",
        "                # Set the 'time' column\n",
        "                #df_features['time'] = ['5'] * len(df_features)\n",
        "\n",
        "                # Reshape the DataFrame to have a single row and 30 columns\n",
        "                df_features = df_features.stack().reset_index(drop=True).to_frame().T\n",
        "\n",
        "                # Display the DataFrame\n",
        "                #print(df_features)\n",
        "\n",
        "                dataset=pd.concat([dataset,df_features],axis=0,ignore_index=True)\n",
        "print(dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "id": "Heb9wnYzSwPI",
        "outputId": "7cdd4098-a70d-46de-ef9c-e09d7cedbdbb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-588892642783>\u001b[0m in \u001b[0;36m<cell line: 15>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m                     \u001b[0;31m# Load the input image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m                     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m                     \u001b[0;31m# Convert the image to grayscale\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m                     \u001b[0mgray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCOLOR_BGR2GRAY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 165
        },
        "id": "A3ySNnM7AXgO",
        "outputId": "39490822-de7f-46d2-c020-b9173376e119"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-04f088450e31>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'dataset' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import pickle\n",
        "'''\n",
        "# Variable to be saved\n",
        "my_variable = dataset\n",
        "\n",
        "# Save the variable to a file\n",
        "with open('/content/gdrive/MyDrive/Project Gait Analysis/Result/dataset features.txt', 'wb') as file:\n",
        "    pickle.dump(my_variable, file)\n",
        "\n",
        "import pickle\n",
        "'''\n",
        "# Load the saved variable from file\n",
        "with open('/content/gdrive/MyDrive/Project Gait Analysis/Result/dataset features.txt', 'rb') as file:\n",
        "    df = pickle.load(file)\n",
        "    column_index=[0,2,6,10,14,18,22]\n",
        "    for i in column_index:\n",
        "      df = df.drop(df.columns[i], axis=1)\n",
        "    filepath = '/content/gdrive/MyDrive/Project Gait Analysis/Result/gait analysis dataset.xlsx'\n",
        "    df.to_excel(filepath, index=False)\n",
        "\n",
        "\n",
        "\n",
        "# Now you can use the loaded variable\n",
        "print(df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FFkYOg12NSGl",
        "outputId": "35789b03-ade2-447e-8939-042c4725806f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "        1          2          4         5      6          7         9   \\\n",
            "0    78043  41.878049  12.235883  0.061837  11325  16.560976  1.397712   \n",
            "1    82102   43.02439   12.30405 -0.071996  12003   17.04878  1.447474   \n",
            "2   101067  41.901961   15.03102  0.223386  15468  17.372549  1.220106   \n",
            "3    72362  41.783784  14.486033  0.074769  11068  17.243243  1.343762   \n",
            "4    17187       16.5   6.784377   0.91736   3655   7.833333  2.514771   \n",
            "..     ...        ...        ...       ...    ...        ...       ...   \n",
            "79   60326  36.684211  15.549759 -0.163242   6383  12.552632  3.225698   \n",
            "80   79990  34.819672   9.944944 -0.043869  13984  15.114754  0.888881   \n",
            "81   54365  26.742424  10.418967   0.23469  13922  14.484848  1.062336   \n",
            "82   44502  27.607843  10.506914  0.346208  11192  14.784314   0.93544   \n",
            "83   70131  33.362069   9.804465 -0.022348  12334  14.551724  0.949998   \n",
            "\n",
            "          10     11         12  ...        19        20     21         22  \\\n",
            "0   2.401924  67045  38.609756  ...  3.351152 -1.515627  66877  38.902439   \n",
            "1   1.414869  73601  40.463415  ...  3.420726 -0.832738  73627  40.756098   \n",
            "2   0.840064  94370  41.058824  ...  3.633117 -0.322835  79869  37.431373   \n",
            "3   0.507729  74031  42.621622  ...  2.993541 -1.287565  63703  39.054054   \n",
            "4  -1.106915  23814  20.037037  ...  5.222518  -0.46646  21016  18.888889   \n",
            "..       ...    ...        ...  ...       ...       ...    ...        ...   \n",
            "79  0.294862  56045  35.921053  ...  5.378795  1.359764  86262  41.631579   \n",
            "80  0.342637  59630  29.901639  ...  1.604046 -1.123678  57188  29.311475   \n",
            "81  1.320983  68094  30.424242  ...  1.584764 -0.724914  61744  28.787879   \n",
            "82  0.305822  56307  31.392157  ...  1.464169 -1.031461  50323  29.431373   \n",
            "83  0.776747  56949  29.810345  ...  1.290342 -0.659289  54155  29.258621   \n",
            "\n",
            "           24        25     26         27        29        30  \n",
            "0    10.85111 -0.126802  67093  40.317073  3.308813 -0.244197  \n",
            "1   11.606938 -0.120595  66352   40.04878  3.799559 -0.313331  \n",
            "2   12.843332  0.241311  82320  39.882353  4.849286 -0.006847  \n",
            "3    14.01726  0.077719  59696       40.0  3.661339  0.124027  \n",
            "4    5.691666  0.280349  16176  16.407407  5.509314 -0.500266  \n",
            "..        ...       ...    ...        ...       ...       ...  \n",
            "79  23.170332  0.786644  31648  27.736842  7.969297  1.569115  \n",
            "80   8.851305  0.020882  58660   30.95082  1.919923  0.527735  \n",
            "81  10.333111  0.194556  58523  29.712121  1.975342  0.195116  \n",
            "82  10.978151  0.375183  47260  30.392157  1.727272   0.18789  \n",
            "83   8.811357  0.048291  53756   30.37931  1.981184 -0.820031  \n",
            "\n",
            "[84 rows x 24 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the saved variable from file\n",
        "with open('/content/gdrive/MyDrive/Project Gait Analysis/Result/array of names in order.txt', 'rb') as file:\n",
        "    df = pickle.load(file)\n",
        "\n",
        "l=[]\n",
        "for i in df:\n",
        "  a=i.split('-')\n",
        "  l.append(a[0])\n",
        "print(l)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wLdHjWh-hUaX",
        "outputId": "31cbe530-f911-46c7-cfc9-612b40e66434"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['wl', 'wl', 'wl', 'wl', 'wyc', 'wyc', 'wyc', 'wyc', 'fyc', 'fyc', 'fyc', 'fyc', 'hy', 'hy', 'hy', 'hy', 'ljg', 'ljg', 'ljg', 'ljg', 'lqf', 'lqf', 'lqf', 'lqf', 'lsl', 'lsl', 'lsl', 'lsl', 'ml', 'ml', 'ml', 'ml', 'nhz', 'nhz', 'nhz', 'nhz', 'rj', 'rj', 'rj', 'rj', 'syj', 'syj', 'syj', 'syj', 'wl', 'wl', 'wl', 'wl', 'wq', 'wq', 'wq', 'wq', 'xch', 'xch', 'xch', 'xch', 'xxj', 'xxj', 'xxj', 'xxj', 'yjf', 'yjf', 'yjf', 'yjf', 'zc', 'zc', 'zc', 'zc', 'zdx', 'zdx', 'zdx', 'zdx', 'zjg', 'zjg', 'zjg', 'zjg', 'zl', 'zl', 'zl', 'zl', 'zyf', 'zyf', 'zyf', 'zyf']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XTYRKSO3iZQS"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}